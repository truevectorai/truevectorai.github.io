[
  {
    "objectID": "learning.html",
    "href": "learning.html",
    "title": "learning",
    "section": "",
    "text": "The earliest use I’ve found of the term machine learning is in the title of a paper by Arthur Samuel (Samuel 1959) which opens with:\n\nThe studies reported here have been concerned with the programming of a digital computer to behave in a way which, if done by human beings or animals, would be described as involving the process of learning.\n\n\n\n\n\nReferences\n\nSamuel, A. L. 1959. “Some Studies in Machine Learning Using the Game of Checkers.” IBM Journal of Research and Development 3 (3): 210–29. https://doi.org/10.1147/rd.33.0210."
  },
  {
    "objectID": "reasoning.html",
    "href": "reasoning.html",
    "title": "reasoning",
    "section": "",
    "text": "In (TURING 1950) Alan Turing came up with his eponymous Turing Test by rewriting his opening question “Can machines think?”\n\n\n\n\n\n\nthe Turing test\n\n\n\n\n\nAlan Turing wasn’t vain enough to have named his thought exercise after himself, and as seen below he called it The Imitation Game. I’ve not found who proposed renaming the concept after him.\n\n\n\n\nI PROPOSE to consider the question, ‘Can machines think?’ This should begin with definitions of the meaning of the terms ‘machine’ and ‘think’. The definitions might be framed so as to reflect so far as possible the normal use of the words, but this attitude is dangerous. If the meaning of the words ‘machine’ and ‘think’ are to be found by examining how they are commonly used it is difficult to escape the conclusion that the meaning and the answer to the question, ‘Can machines think?’ is to be sought in a statistical survey such as a Gallup poll. But this is absurd. Instead of attempting such a definition I shall replace the question by another, which is closely related to it and is expressed in relatively unambiguous words.\n\n\nThe new form of the problem can be described in terms of a game which we call the ‘imitation game’. It is played with three people, a man (A), a woman (B), and an interrogator (C) who may be of either sex. The interrogator stays in a room apart from the other two. The object of the game for the interrogator is to determine which of the other two is the man and which is the woman. He knows them by labels X and Y, and at the end of the game he says either ‘X is A and Y is B’ or ‘X is B and Y is A’. The interrogator is allowed to put questions to A and B thus:\n\n\nC: Will X please tell me the length of his or her hair? Now suppose X is actually A, then A must answer. It is A’s object in the game to try and cause C to make the wrong identification. His answer might therefore be\n\n\n‘My hair is shingled, and the longest strands are about nine inches long.’\n\n\nIn order that tones of voice may not help the interrogator the answers should be written, or better still, typewritten. The ideal arrangement is to have a teleprinter communicating between the two rooms. Alternatively the question and answers can be repeated by an intermediary. The object of the game for the third player (B) is to help the interrogator. The best strategy for her is probably to give truthful answers. She can add such things as ‘I am the woman, don’t listen to him!’ to her answers, but it will avail nothing as the man can make similar remarks.\n\n\nWe now ask the question, ‘What will happen when a machine takes the part of A in this game?’ Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, ‘Can machines think?’\n\n\n\n\n\nReferences\n\nTURING, A. M. 1950. “I.—COMPUTING MACHINERY AND INTELLIGENCE.” Mind LIX (236): 433–60. https://doi.org/10.1093/mind/lix.236.433."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "true vector",
    "section": "",
    "text": "πόλλ’ οἶδ’ ἀλώπηξ, ἀλλ’ ἐχῖνος ἓν μέγα Ἀρχίλοχος\n\n\n\n\n\n\n\nMultiple passes…\n\n\n\n\n\n\n\n\n\n\n\n\n\n…of meandering musings, including but not limited to the rather broad field of artificial intelligence along with its various foci of effort.\n\n\n\n\n\n\nThe meandering muser…\n\n\n\n\n\n\n\n\n\n\n\n…is a semi-retired über-curious specialized-generalist, who lived as a child for several years with his dirt-poor grandparents (near literally, as their floor was actually unfinished wood) on a too-big tenant-farm, with a first paying-job as a department-store janitor while in high school (but with talent suitably recognized, was rapidly upgraded to cleaning the gerbil cages after less than a month), moving into house carpentry and construction to make enough money for, and continuing that occupation throughout, college, with (likely excessive) extracurricular activities as a sports photographer, then a career as a USAF officer, followed by a brief stint as a private investor, publicly-traded-company board member, then appointed by a federal judge as a small-cap CEO to effect recovery of embezzled funds which involved some international detective work, on to participating in an aviation manufacturing startup, and finally scraping the rust off the degree and engaging as a cyber-security systems-engineer in the IT field for the last couple of decades, though frequently enjoying the odd foray into new domains along the way.\n\n\n\n\n\n\non specialists\n\n\n\n\n\n“The dilemma is this. In the modern world knowledge has been growing so fast and so enormously, in almost every field, that the probabilities are immensely against anybody, no matter how innately clever, being able to make a contribution in any one field unless he devotes all his time to it for years. If he tries to be the Rounded Universal Man, like Leonardo da Vinci, or to take all knowledge for his province, like Francis Bacon, he is most likely to become a mere dilettante and dabbler. But if he becomes too specialized, he is apt to become narrow and lopsided, ignorant on every subject but his own, and perhaps dull and sterile even on that because he lacks perspective and vision and has missed the cross-fertilization of ideas that can come from knowing something of other subjects.”\nHenry Hazlitt\n\n\n\n\n\n\n\n\n\non generalists\n\n\n\n\n\n“A human being should be able to change a diaper, plan an invasion, butcher a hog, conn a ship, design a building, write a sonnet, balance accounts, build a wall, set a bone, comfort the dying, take orders, give orders, cooperate, act alone, solve equations, analyze a new problem, pitch manure, program a computer, cook a tasty meal, fight efficiently, die gallantly. Specialization is for insects.”\nLazurus Long as written by Robert Heinlein in Time Enough for Love\n\n\n\n\n\n\n\n\n\na lot of a little and a little of a lot\n\n\n\n\n\nspecialized generalist - aka one who cannot make up his mind…\n“These are the principles for the development of a complete mind: Study the science of art. Study the art of science. Learn to see. Realize that everything connects to everything else.”\nLeonardo da Vinci\n“I suppose it is tempting, if the only tool you have is a hammer, to treat everything as if it were a nail.”\nMaslow’s Hammer\nWithout a broad foundation, it’s facile to slide into confirmation bias by “seeking or interpreting of evidence in ways that are partial to existing beliefs”.\n\n\n\n\n\n\n\n\n\nerr…wikipedia?\n\n\n\n\n\nThe astute reader will notice the occasional academic faux pas of linking to Wikipedia articles. What contrarian blush has come over the author?\n\nHD: When I use a word, it means just what I choose it to mean—neither more nor less. AL: The question is, whether you can make words mean different things. HD: The question is, which is to be master—that’s all. Impenetrability! That’s what I say!\n\n– captured snippet of conversation with well known entropy demonstrator Mr. Dumpty and dysmegalopsiac adventurer Ms. Liddell\nalso, as per a reliable source…\n\n\n\n\n\n\n\n\n\none ping only\n\n\n\n\n\n\nnavigationphysicsmathai\n\n\nThe speed and direction of a target relative to a reference point (usually the Geographic [true] North Pole) is called its true vector, and is where this site drew the inspiration for its name, though from the similar application in aviation. If done with modern sonar there is some beamforming to give an angle (bearing) to the reflection (target), while older submarines would have had much less angular precision and would have to rely on more on estimation of own movement to calculate a phase shift in returned signals after a known time and distance change of the observer. Fighter aircraft radar is similar though modern airborne radar can be steered very specifically and precisely with high resolution. To calcuate this an observer generally measures the velocity of the target relative to the observer and then performs a translation (with ever more useful computational capability) of that vector to the reference point.\n\n\n\n\n\n\n\n\n\nA true vector or radius vector reverses sign if the coordinate axes are reversed. Examples of polar vectors include r, the velocity vector v, momentum p, and force F.\n\n\n\n\n\n\n\n\n\nA true vector or polar vector is a representation of a vector as a magnitude (length) and angle, which is equivalent to specifying its endpoints in polar coordinates.\n\n\n\n\n\n\n\n\n\nA true vector as defined in the navigation tab could be likened in machine learning (well, at least by me) to attempting to determine the “goldilocks” (neither underfit nor overfit) prediction path by application of optimization algorithms to datasets of observations."
  },
  {
    "objectID": "knowledge.html",
    "href": "knowledge.html",
    "title": "knowledge",
    "section": "",
    "text": "In what the paywalled citation (FEIGENBAUM 1984) references and appears to be a republishing of his 1980 paper of the same name in the Stanford archives, Edward Feigenbaum coins the term Knowledge Engineering, and discusses symbolic computation and inference, and makes the distinctions about the facts vs the heuristics of a domain, and that the application of expert-rules, or as he aptly shares from George Polya, “the art of good guessing” are what constitute the rules of good practice, judgment, and expertise.\n\n\n\n\nReferences\n\nFEIGENBAUM, EDWARD A. 1984. “Knowledge Engineering.” Annals of the New York Academy of Sciences 426 (1 Computer Cult): 91–107. https://doi.org/10.1111/j.1749-6632.1984.tb16513.x."
  },
  {
    "objectID": "affective.html",
    "href": "affective.html",
    "title": "affective",
    "section": "",
    "text": "Rosalind Picard introduced the term in her 1995 paper Affective Computing (and followed up with the cited 2000 book (Picard 2000) by the same name) in which she postulated in the Abstract that\n\nComputers are beginning to acquire the ability to express and recognize affect, and may soon be given the ability to “have emotions.” The essential role of emotion in both human cognition and perception, as demonstrated by recent neurological studies, indicates that affective computers should not only provide better performance in assisting humans, but also might enhance computers’ abilities to make decisions. This paper presents and discusses key issues in “affective computing,” computing that relates to, arises from, or influences emotions. Models are suggested for computer recognition of human emotion, and new applications are presented for computer-assisted learning, perceptual information retrieval, arts and entertainment, and human health and interaction. Affective computing, coupled with new wearable computers, will also provide the ability to gather new data necessary for advances in emotion and cognition theory.\n\n\n\n\n\nReferences\n\nPicard, Rosalind W. 2000. “Affective Computing.” The MIT Press. https://doi.org/10.7551/mitpress/1140.001.0001."
  }
]